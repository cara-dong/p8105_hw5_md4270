---
title: "Homework5"
author: "Manye Dong"
date: "2023-11-06"
output: github_document
---
```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

## Problem 1
```{r message=FALSE, warning=FALSE}
homicide = read_csv("datasets/homicide-data.csv")
head(homicide)
```
```{r message=FALSE, warning=FALSE}
homicide_clean =
  homicide |>
  janitor::clean_names() |>
  mutate(state = replace(state, state == "wI", "WI")) |> 
  mutate(city_state = paste(city, state, sep = ", ")) |>
  filter(city_state != "Tulsa, AL") |> 
  drop_na()
```

The data has `r nrow(homicide_clean)` rows and `r ncol(homicide_clean)` columns. Important features include xxx

```{r message=FALSE, warning=FALSE}
homicide_summarize = 
  homicide_clean |>
  group_by(city_state) |>
  summarise(total_homicide = n(), 
            unsolved_homicide = sum(disposition %in% c("Closed without arrest", "Open/No arrest")))

homicide_summarize
```

```{r message=FALSE, warning=FALSE}
homicide_prop_test = 
  homicide_clean |>
  filter(city_state == "Baltimore, MD")

unsolved_count = sum(homicide_prop_test$disposition %in% c("Closed without arrest", "Open/No arrest"))

total_homicides = nrow(homicide_prop_test)

prop_test_result = prop.test(x = unsolved_count, n = total_homicides)
```

```{r message=FALSE, warning=FALSE}
tidy_result = broom::tidy(prop_test_result)

tidy_result = 
  tidy_result |>
  select(estimate, conf.low, conf.high)

tidy_result
```
Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r message=FALSE, warning=FALSE}
run_prop_test = function(total, unsolved) {
  prop.test(x = unsolved, n = total)
}
```

```{r message=FALSE, warning=FALSE}
nested_data = 
  homicide_clean |>
  group_by(city_state) |>
  summarize(total_homicide = n(), 
            unsolved_homicide = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))) |>
  nest(data = c(total_homicide, unsolved_homicide))
```

```{r message=FALSE, warning=FALSE}
results = 
  nested_data |>
  mutate(prop_test_results = map(data, ~run_prop_test(.x$total_homicide, .x$unsolved_homicide))) |>
  mutate(tidy_results = map(prop_test_results, broom::tidy)) |>
  select(city_state, tidy_results) |>
  unnest(tidy_results) |>
  select(city_state, estimate, conf.low, conf.high)

head(results)
```
Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.
```{r fig.width=12, fig.height=8, message=FALSE, warning=FALSE}
results$city_state <- factor(results$city_state, levels = results$city_state[order(results$estimate)])

ggplot(results, aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(x = "City", y = "Proportion of Unsolved Homicides", title = "Proportion of Unsolved Homicides by City") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```


## Problem 2
```{r message=FALSE, warning=FALSE}
longitudinal = function(path,filename) {
  
  df = 
    read_csv(path) |>
    janitor::clean_names() |>
    mutate(id = filename) |>
    pivot_longer(
      cols = -id,
      names_to = "week",
      values_to = "value",
      names_prefix = "week_") |>
    separate(id,c("arm", "subject_id"),  sep = "_") |>
    mutate(
      arm = recode(arm, con = "control", exp = "experimental"),
      subject_id = gsub("\\.csv$","",subject_id))

  df
}
```

```{r message=FALSE, warning=FALSE}
files = list.files("./datasets/study_data", full.names = TRUE)
```

```{r message=FALSE, warning=FALSE}
tidied_df = 
  purrr::map(files, ~ longitudinal(.x, basename(.x))) |> 
  bind_rows()
```

Make sure weekly observations are tidy:
```{r message=FALSE, warning=FALSE}
tidied_df |>
  group_by(week) |> 
  summarise(n = n())
```

```{r message=FALSE, warning=FALSE}
tidied_df |>
  group_by(subject_id) |> 
  summarise(n = n())   
```

```{r message=FALSE, warning=FALSE}
tidied_df |>
  group_by(week, subject_id) |> 
  summarise(n = n())
```
Make a spaghetti plot:
```{r message=FALSE, warning=FALSE}
tidied_df |>
  ggplot(aes(x = week, y = value, color = subject_id)) +
  geom_line(aes(group = subject_id), se = FALSE) +
  facet_grid(~arm) +
  scale_color_brewer(palette = "Set3") + 
  labs(x = "Week", y = "Value", title = "Value Change Across Two Groups", col = "Subject ID")
```

Observations: 


## Problem 3
```{r message=FALSE, warning=FALSE}
set.seed(1)
```

Define a function to get the true simulated mu and sigma:
```{r message=FALSE, warning=FALSE}
true_mean_sd = function(n = 30, mu, sigma = 5) {
  dataset = rnorm(n, mean = mu, sd = sigma)
  table = data.frame(
    true_mu = mean(dataset),
    true_sigma = sd(dataset))
  
  table
}
```

Conduct one-sample t-test for one dataset:
```{r message=FALSE, warning=FALSE}
t_test = function(n = 30, mu, sigma = 5) {
  dataset = rnorm(n, mean = mu, sd = sigma)
  result = t.test(dataset, mu = 0, alternative = "two.sided", conf.level = 0.95) |>
    broom::tidy() |>
    select(estimate, p.value)
  
  result
}
```

Create a data frame to store the results:
```{r message=FALSE, warning=FALSE}
result_df = data.frame(
  mu = numeric(), 
  mu_hat = numeric(), 
  p_value = numeric(), 
  rejected = logical())
```


```{r message=FALSE, warning=FALSE}
for (mu in c(0, 1, 2, 3, 4, 5, 6)) {
  for (i in 1:5000) {
    simulations = true_mean_sd(n=30, mu, sigma=5)
    t_test_results = t_test(n=30, mu, sigma=5)
    result_df = result_df |> 
      add_row(mu = mu, 
              mu_hat = simulations$true_mu,
              p_value = t_test_results$p.value, 
              rejected = t_test_results$p.value < 0.05)
  }
}
```

Create a plot for association between true_mu and rejected_prop
```{r message=FALSE, warning=FALSE}
association = 
  result_df |> 
  group_by(mu) |> 
  summarise(n_reject = sum(rejected==TRUE), 
            total = n(), 
            prop_reject = sum(rejected==TRUE)/total)

head(association)
```
```{r message=FALSE, warning=FALSE}
association |>
  ggplot(aes(x = mu, y = prop_reject)) +
  geom_point() +
  geom_line() +
  labs(title = "Proportion that Rejected Null vs. True Mean", x = "True Mean (mu)", y = "Proportion that Rejected Null")
```

The line plot above indicates a positive association between true value of mu and the proportion of times the null was rejected. As the true value of mu increases, the power of the test increases along with it. When mu reaches 5 and 6, almost all tests show an result of rejecting the null.

Create a plot for average mu_hat vs mu:
```{r message=FALSE, warning=FALSE}
# create a plot average estimate of μ̂ on the y axis and the true value of μ on the x axis for all samples

```

